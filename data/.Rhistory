# loading packages and data -----------------------------------------------
if (!require(tm)) install.packages("tm"); require(tm)
if (!require(wordcloud)) install.packages("wordcloud"); require(wordcloud)
#library(car)
library(psych)
library(effects)
rm(list = ls())
setwd('/Users/stevenfelix/Dropbox/JobSearch/DataScienceProjects/PsychologyToday')
data <- read.table('psychologytoday2017-02-17.txt', sep = '\t', header = TRUE, stringsAsFactors = FALSE)
#View(data)
table(data$title)
data <- data[data$title != 'treatment facility',]
setwd('/Users/stevenfelix/Dropbox/JobSearch/DataScienceProjects/PsychologyToday/data/PsychologyToday')
setwd('/Users/stevenfelix/Dropbox/JobSearch/DataScienceProjects/PsychologyToday/data/')
data <- read.table('psychologytoday2017-02-17.txt', sep = '\t', header = TRUE, stringsAsFactors = FALSE)
#View(data)
# loading packages and data -----------------------------------------------
if (!require(tm)) install.packages("tm"); require(tm)
if (!require(wordcloud)) install.packages("wordcloud"); require(wordcloud)
#library(car)
library(psych)
library(effects)
rm(list = ls())
setwd('/Users/stevenfelix/Dropbox/JobSearch/DataScienceProjects/PsychologyToday/data/')
data <- read.table('psychologytoday2017-02-17.txt', sep = '\t', header = TRUE, stringsAsFactors = FALSE)
#View(data)
table(data$title)
data <- data[data$title != 'treatment facility',]
if (!require(tm)) install.packages("tm"); require(tm)
if (!require(wordcloud)) install.packages("wordcloud"); require(wordcloud)
# read in the first book
fname <- 'http://www.gutenberg.org/files/1342/1342-0.txt'
download.file(url=fname,destfile='book1.txt', method = 'curl') # download book
book1 <- readChar('book1.txt', file.info('book1.txt')$size)
# read in the second book
fname <- 'http://www.gutenberg.org/cache/epub/145/pg145.txt'
download.file(url=fname,destfile='book2.txt', method = 'curl') # download book
book2 <- readChar('book2.txt', file.info('book2.txt')$size)
# put books together
books <- c(book1,book2)
# convert the books to corpora with the tm package
corpus <- Corpus(VectorSource(books))
# create term-document matrix
tdm <- TermDocumentMatrix(corpus,control = list(
removePunctuation = TRUE, # remove punctuation
stopwords = TRUE, # remove stopwords (high frequency)
tolower = TRUE, # make all lower case
removeNumbers = TRUE, # remove numbers
bounds = list(local=c(2,Inf)))) # only include cases with at least two occurences
tdm <- as.matrix(tdm)
tdm
## basis of its similarity to the other two.
if (!require("lsa")) {install.packages("lsa"); library("lsa")} # needed for cosine distance
fname <- 'http://www.gutenberg.org/cache/epub/7469/pg7469.txt'
download.file(url=fname,destfile='book3.txt', method = 'curl') # download book
book3 <- readChar('book3.txt', file.info('book3.txt')$size)
# put books together
books <- c(book1,book2,book3)
# convert the books to corpora with the tm package
corpus <- Corpus(VectorSource(books))
books <- data$treatmentapproach
corpus <- Corpus(VectorSource(books))
# create term-doument matrix
tdm <- TermDocumentMatrix(corpus,control = list(
removePunctuation = TRUE, # remove punctuation
stopwords = TRUE, # remove stopwords (high frequency)
tolower = TRUE, # make all lower case
removeNumbers = TRUE, # remove numbers
bounds = list(local=c(10,Inf)))) # only include cases with at least two occurences
tdm <- as.matrix(tdm)
tdm
cosine(tdm)
cosmat <- cosine(tdm)
head(tdm)
View(tdm)
tdm <- TermDocumentMatrix(corpus,control = list(
removePunctuation = TRUE, # remove punctuation
stopwords = TRUE, # remove stopwords (high frequency)
tolower = TRUE, # make all lower case
removeNumbers = TRUE, # remove numbers
bounds = list(local=c(10,Inf)))) # only include cases with at least two occurences
tdm <- as.matrix(tdm)
tdm <- TermDocumentMatrix(corpus,control = list(
removePunctuation = TRUE, # remove punctuation
stopwords = TRUE, # remove stopwords (high frequency)
tolower = TRUE, # make all lower case
removeNumbers = TRUE, # remove numbers
bounds = list(local=c(10,Inf)))) # only include cases with at least two occurences
tdm[[1]]
tdm[[2]]
tdm[[3]]
tdm <- TermDocumentMatrix(corpus,control = list(
removePunctuation = TRUE, # remove punctuation
stopwords = FALSE, # remove stopwords (high frequency)
tolower = TRUE, # make all lower case
removeNumbers = TRUE, # remove numbers
bounds = list(local=c(10,Inf)))) # only include cases with at least two occurences
tdm <- as.matrix(tdm)
books <- data$treatmentapproach
data$treatmentapproach
data$treatmentapproach
# loading packages and data -----------------------------------------------
if (!require(tm)) install.packages("tm"); require(tm)
if (!require(wordcloud)) install.packages("wordcloud"); require(wordcloud)
#library(car)
library(psych)
library(effects)
rm(list = ls())
setwd('/Users/stevenfelix/Dropbox/JobSearch/DataScienceProjects/PsychologyToday/data/')
data <- read.table('psychologytoday2017-02-17.txt', sep = '\t', header = TRUE, stringsAsFactors = FALSE)
#View(data)
table(data$title)
data <- data[data$title != 'treatment facility',]
data$treatmentapproach
data <- read.table('psychologytoday2017-02-17.txt', sep = '\t', header = TRUE, stringsAsFactors = FALSE)
View(data)
books <- data$treatmentorientation
books[3]
corpus <- Corpus(VectorSource(books))
# create term-doument matrix
tdm <- TermDocumentMatrix(corpus,control = list(
removePunctuation = TRUE, # remove punctuation
stopwords = TRUE, # remove stopwords (high frequency)
tolower = TRUE, # make all lower case
removeNumbers = TRUE, # remove numbers
bounds = list(local=c(10,Inf)))) # only include cases with at least two occurences
tdm <- as.matrix(tdm)
tdm[1:30,1:10]
data$treatmentorientation
books <- data$treatmentorientation
# convert the books to corpora with the tm package
corpus <- Corpus(VectorSource(books))
# create term-doument matrix
tdm <- TermDocumentMatrix(corpus,control = list(
removePunctuation = TRUE, # remove punctuation
stopwords = TRUE, # remove stopwords (high frequency)
tolower = TRUE, # make all lower case
removeNumbers = TRUE, # remove numbers
bounds = list(local=c(10,Inf)))) # only include cases with at least two occurences
tdm <- as.matrix(tdm)
install.packages("RSiteCatalyst")
install.packages("RTextTools")
library("RTextTools") #Loads many packages useful for text mining
dtm <- create_matrix(data$treatmentorientation,
stemWords=TRUE,
removeStopwords=FALSE,
minWordLength=3,
removePunctuation= TRUE)
findFreqTerms(dtm, lowfreq=20)
findFreqTerms(dtm, lowfreq=15)
findFreqTerms(dtm, lowfreq=10)
findFreqTerms(dtm, lowfreq=2)
findFreqTerms(dtm, lowfreq=20)
findFreqTerms(dtm, lowfreq=50)
findFreqTerms(dtm, lowfreq=100)
findFreqTerms(dtm, lowfreq=200)
findFreqTerms(dtm, lowfreq=500)
findFreqTerms(dtm, lowfreq=500)
findFreqTerms(dtm, lowfreq=400)
kmeans5<- kmeans(dtm, 5)
kw_with_cluster <- as.data.frame(cbind(data$treatmentorientation, kmeans5$cluster))
c("keyword", "kmeans5")
names(kw_with_cluster) <- c("treatmentorientation", "kmeans5")
cluster1 <- subset(kw_with_cluster, subset=kmeans5 == 1)
cluster2 <- subset(kw_with_cluster, subset=kmeans5 == 2)
cluster3 <- subset(kw_with_cluster, subset=kmeans5 == 3)
cluster4 <- subset(kw_with_cluster, subset=kmeans5 == 4)
cluster5 <- subset(kw_with_cluster, subset=kmeans5 == 5)
cluster1
View(cluster1)
length(cluster1)
numrows(cluster1)
num.rows(cluster1)
num.row(cluster1)
dim(cluster1)
dim(cluster2)
?solve
for(i in 1:5)
{
paste("cluster",i)
}
for(i in 1:5)
{
print(paste("cluster",i))
}
clusters <- NULL
for(i in 1:5)
{
clusters <- c(clusters,(paste("cluster",i,sep="")))
}
clusters
for(i in clusters)
{
print i
}
for(i in clusters)
{
print(i)
}
for(i in 1:5)
{
cluster <- paste("cluster",i,sep="")
print(dim(eval(cluster)))
}
for(i in 1:5)
{
cluster <- paste("cluster",i,sep="")
print(cluster)
#print(dim(eval(cluster)))
}
for(i in 1:5)
{
cluster <- paste("cluster",i,sep="")
print(eval(cluster))
#print(dim(eval(cluster)))
}
for(i in 1:5)
{
cluster <- paste("cluster",i,sep="")
print(dim(eval(parse(cluster))))
#print(dim(eval(cluster)))
}
dim(cluster2)
View(cluster2)
dim(cluster3)
dim(cluster3)
View(cluster3)
.
cost_df <- data.frame()
#run kmeans for all clusters up to 100
for(i in 1:100){
#Run kmeans for each level of i, allowing up to 100 iterations for convergence
kmeans<- kmeans(x=dtm, centers=i, iter.max=100)
#Combine cluster number and cost together, write to df
cost_df<- rbind(cost_df, cbind(i, kmeans$tot.withinss))
}
names(cost_df) <- c("cluster", "cost")
